{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7ae82d-bf6c-461e-ac31-a77387679b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878dd7f-a8d4-480c-9f5a-62a47955502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://drive.google.com/file/d/1S7upK1OsxQoLfOLDTR-Px3XJFGuZKn3B/view?usp=sharing\n",
    "!gdown https://drive.google.com/uc?id=1S7upK1OsxQoLfOLDTR-Px3XJFGuZKn3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f23b5-4233-46ae-bcf9-514ac8c3c44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r TLDataset/ALL/PKG-C-NMC2019/train/.ipynb_checkpoints\n",
    "!rm -r TLDataset/ALL/PKG-C-NMC2019/train/.DS_STORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba421ba6-36bf-4670-b383-36db6d2689a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import ConvNeXt_Base_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bb23ab-30a3-48b8-bb78-db3a6c0b9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a78e27-8429-4008-91d4-8f3fa90f9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade efficientnet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6cf85b-d1b8-4c43-b4db-5771ea331fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108240b1-5af9-46ae-af10-0d3a4035ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f3f109-f561-43de-846b-e927f1b9fe17",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e15992db",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Training Data: 7845 samples\n",
      "Validation Data: 2347 samples\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─PatchEmbed: 1-1                        [-1, 196, 768]            --\n",
      "|    └─Conv2d: 2-1                       [-1, 768, 14, 14]         590,592\n",
      "|    └─Identity: 2-2                     [-1, 196, 768]            --\n",
      "├─Dropout: 1-2                           [-1, 197, 768]            --\n",
      "├─Identity: 1-3                          [-1, 197, 768]            --\n",
      "├─Identity: 1-4                          [-1, 197, 768]            --\n",
      "├─Sequential: 1-5                        [-1, 197, 768]            --\n",
      "|    └─Block: 2-3                        [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-1               [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-2               [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-3                [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-4                [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-5               [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-6                     [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-7                [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-8                [-1, 197, 768]            --\n",
      "|    └─Block: 2-4                        [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-9               [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-10              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-11               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-12               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-13              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-14                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-15               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-16               [-1, 197, 768]            --\n",
      "|    └─Block: 2-5                        [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-17              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-18              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-19               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-20               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-21              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-22                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-23               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-24               [-1, 197, 768]            --\n",
      "|    └─Block: 2-6                        [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-25              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-26              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-27               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-28               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-29              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-30                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-31               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-32               [-1, 197, 768]            --\n",
      "|    └─Block: 2-7                        [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-33              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-34              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-35               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-36               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-37              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-38                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-39               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-40               [-1, 197, 768]            --\n",
      "|    └─Block: 2-8                        [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-41              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-42              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-43               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-44               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-45              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-46                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-47               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-48               [-1, 197, 768]            --\n",
      "|    └─Block: 2-9                        [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-49              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-50              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-51               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-52               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-53              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-54                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-55               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-56               [-1, 197, 768]            --\n",
      "|    └─Block: 2-10                       [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-57              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-58              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-59               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-60               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-61              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-62                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-63               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-64               [-1, 197, 768]            --\n",
      "|    └─Block: 2-11                       [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-65              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-66              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-67               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-68               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-69              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-70                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-71               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-72               [-1, 197, 768]            --\n",
      "|    └─Block: 2-12                       [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-73              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-74              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-75               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-76               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-77              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-78                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-79               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-80               [-1, 197, 768]            --\n",
      "|    └─Block: 2-13                       [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-81              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-82              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-83               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-84               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-85              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-86                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-87               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-88               [-1, 197, 768]            --\n",
      "|    └─Block: 2-14                       [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-89              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-90              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-91               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-92               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-93              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-94                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-95               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-96               [-1, 197, 768]            --\n",
      "├─LayerNorm: 1-6                         [-1, 197, 768]            1,536\n",
      "├─Identity: 1-7                          [-1, 768]                 --\n",
      "├─Dropout: 1-8                           [-1, 768]                 --\n",
      "├─Linear: 1-9                            [-1, 2]                   1,538\n",
      "==========================================================================================\n",
      "Total params: 85,648,130\n",
      "Trainable params: 85,648,130\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 455.99\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 154.67\n",
      "Params size (MB): 326.72\n",
      "Estimated Total Size (MB): 481.97\n",
      "==========================================================================================\n",
      "Epoch [1/50], Train Loss: 0.7866, LR: 0.001000                                  \n",
      "Validation Loss: 0.0216, F1: 0.5304\n",
      "Saved Best Model at epoch 1 with F1 score: 0.5304\n",
      "Epoch [2/50], Train Loss: 0.5736, LR: 0.001000                                  \n",
      "Validation Loss: 0.0247, F1: 0.3622\n",
      "Epoch [3/50], Train Loss: 0.5476, LR: 0.001000                                  \n",
      "Validation Loss: 0.0174, F1: 0.6934\n",
      "Saved Best Model at epoch 3 with F1 score: 0.6934\n",
      "Epoch [4/50], Train Loss: 0.5041, LR: 0.001000                                  \n",
      "Validation Loss: 0.0155, F1: 0.7291\n",
      "Saved Best Model at epoch 4 with F1 score: 0.7291\n",
      "Epoch [5/50], Train Loss: 0.4667, LR: 0.000100                                  \n",
      "Validation Loss: 0.0251, F1: 0.6035\n",
      "Epoch [6/50], Train Loss: 0.4305, LR: 0.000100                                  \n",
      "Validation Loss: 0.0137, F1: 0.7690\n",
      "Saved Best Model at epoch 6 with F1 score: 0.7690\n",
      "Epoch [7/50], Train Loss: 0.4088, LR: 0.000100                                  \n",
      "Validation Loss: 0.0134, F1: 0.7666\n",
      "Epoch [8/50], Train Loss: 0.3970, LR: 0.000100                                  \n",
      "Validation Loss: 0.0137, F1: 0.7926\n",
      "Saved Best Model at epoch 8 with F1 score: 0.7926\n",
      "Epoch [9/50], Train Loss: 0.3904, LR: 0.000100                                  \n",
      "Validation Loss: 0.0129, F1: 0.8031\n",
      "Saved Best Model at epoch 9 with F1 score: 0.8031\n",
      "Epoch [10/50], Train Loss: 0.3808, LR: 0.000010                                 \n",
      "Validation Loss: 0.0130, F1: 0.8124\n",
      "Saved Best Model at epoch 10 with F1 score: 0.8124\n",
      "Epoch [11/50], Train Loss: 0.3472, LR: 0.000010                                 \n",
      "Validation Loss: 0.0121, F1: 0.8186\n",
      "Saved Best Model at epoch 11 with F1 score: 0.8186\n",
      "Epoch [12/50], Train Loss: 0.3392, LR: 0.000010                                 \n",
      "Validation Loss: 0.0122, F1: 0.8213\n",
      "Saved Best Model at epoch 12 with F1 score: 0.8213\n",
      "Epoch [13/50], Train Loss: 0.3355, LR: 0.000010                                 \n",
      "Validation Loss: 0.0120, F1: 0.8223\n",
      "Saved Best Model at epoch 13 with F1 score: 0.8223\n",
      "Epoch [14/50], Train Loss: 0.3309, LR: 0.000010                                 \n",
      "Validation Loss: 0.0119, F1: 0.8238\n",
      "Saved Best Model at epoch 14 with F1 score: 0.8238\n",
      "Epoch [15/50], Train Loss: 0.3263, LR: 0.000001                                 \n",
      "Validation Loss: 0.0120, F1: 0.8277\n",
      "Saved Best Model at epoch 15 with F1 score: 0.8277\n",
      "Epoch [16/50], Train Loss: 0.3204, LR: 0.000001                                 \n",
      "Validation Loss: 0.0118, F1: 0.8268\n",
      "Epoch [17/50], Train Loss: 0.3184, LR: 0.000001                                 \n",
      "Validation Loss: 0.0118, F1: 0.8247\n",
      "Epoch [18/50], Train Loss: 0.3171, LR: 0.000001                                 \n",
      "Validation Loss: 0.0119, F1: 0.8237\n",
      "Epoch [19/50], Train Loss: 0.3165, LR: 0.000001                                 \n",
      "Validation Loss: 0.0119, F1: 0.8249\n",
      "Epoch [20/50], Train Loss: 0.3157, LR: 0.000000                                 \n",
      "Validation Loss: 0.0118, F1: 0.8252\n",
      "Epoch [21/50], Train Loss: 0.3146, LR: 0.000000                                 \n",
      "Validation Loss: 0.0118, F1: 0.8252\n",
      "Epoch [22/50], Train Loss: 0.3145, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [23/50], Train Loss: 0.3145, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8247\n",
      "Epoch [24/50], Train Loss: 0.3144, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [25/50], Train Loss: 0.3143, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [26/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [27/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [28/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [29/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [30/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [31/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [32/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [33/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [34/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [35/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [36/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [37/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [38/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [39/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [40/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [41/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [42/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [43/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [44/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [45/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [46/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [47/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [48/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [49/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "Epoch [50/50], Train Loss: 0.3142, LR: 0.000000                                 \n",
      "Validation Loss: 0.0119, F1: 0.8252\n",
      "\n",
      "Training completed in 3690.6s\n",
      "\n",
      "--- Overall Metrics ---\n",
      "Precision: 0.8497\n",
      "Recall: 0.8099\n",
      "F1 Score: 0.8252\n",
      "Accuracy: 0.8564\n",
      "Balanced Accuracy: 0.8099\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "!python train-vt.py --model_name vit_base_patch16_224 --data_dir TLDataset/ALL/PKG-C-NMC2019 --num_classes 2 --num_epochs 50 --batch_size 32 --learning_rate 0.001 --checkpoint_path model_checkpoints/ALL/vit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03bb30-e65d-4f22-9213-44ef17cccb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90a4a864-c4fa-40de-b207-05336b0f4beb",
   "metadata": {},
   "source": [
    "# Evaluation \n",
    "\n",
    "ALL Only Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c61cd37-0ede-4a2a-8353-94910fae14cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "Precision: 0.8158\n",
      "Recall: 0.8147\n",
      "F1: 0.8152\n",
      "Accuracy: 0.8401\n",
      "Balanced accuracy: 0.8147\n"
     ]
    }
   ],
   "source": [
    "!python evaluate_vt.py --model_name vit_base_patch16_224 --data_dir ALL_Unseen/ --model_path model_checkpoints/ALL/vit/vit_base_patch16_224_best.pth --num_classes 2 --batch_size 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb581df-9faf-44e5-b135-499c99ab68e6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a63217-57a1-4ac8-b0b5-1b409e98f2f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python inference.py --model_name resnet50 --image_path TLDataset/ALL/PKG-C-NMC2019/C-NMC_test_prelim_phase_data --model_path model_checkpoints/ALL/resnet50_best_epoch_49.pth --num_classes 2 --image_save results_C-NMC_test_prelim_phase_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33031b9-630d-4a23-a9a1-3319e0980927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python inference.py --model_name resnet50 --image_path TLDataset/ALL/PKG-C-NMC2019/C-NMC_test_final_phase_data --model_path model_checkpoints/ALL/resnet50_best_epoch_49.pth --num_classes 2 --image_save results_C-NMC_test_final_phase_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992d1e61-5a44-46f2-a8ad-d32c1bb4f6b1",
   "metadata": {},
   "source": [
    "# Transfer learning \n",
    "\n",
    "Here the trained model on ALL dataset is finetuned for AML dataset, by loading the ALL model weights as pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b19e54e7-77ed-4a79-b46d-fcf72a25af8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Training Data: 12207 samples\n",
      "Validation Data: 5230 samples\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─PatchEmbed: 1-1                        [-1, 196, 768]            --\n",
      "|    └─Conv2d: 2-1                       [-1, 768, 14, 14]         590,592\n",
      "|    └─Identity: 2-2                     [-1, 196, 768]            --\n",
      "├─Dropout: 1-2                           [-1, 197, 768]            --\n",
      "├─Identity: 1-3                          [-1, 197, 768]            --\n",
      "├─Identity: 1-4                          [-1, 197, 768]            --\n",
      "├─Sequential: 1-5                        [-1, 197, 768]            --\n",
      "|    └─Block: 2-3                        [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-1               [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-2               [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-3                [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-4                [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-5               [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-6                     [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-7                [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-8                [-1, 197, 768]            --\n",
      "|    └─Block: 2-4                        [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-9               [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-10              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-11               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-12               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-13              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-14                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-15               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-16               [-1, 197, 768]            --\n",
      "|    └─Block: 2-5                        [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-17              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-18              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-19               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-20               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-21              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-22                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-23               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-24               [-1, 197, 768]            --\n",
      "|    └─Block: 2-6                        [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-25              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-26              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-27               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-28               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-29              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-30                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-31               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-32               [-1, 197, 768]            --\n",
      "|    └─Block: 2-7                        [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-33              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-34              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-35               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-36               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-37              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-38                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-39               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-40               [-1, 197, 768]            --\n",
      "|    └─Block: 2-8                        [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-41              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-42              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-43               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-44               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-45              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-46                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-47               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-48               [-1, 197, 768]            --\n",
      "|    └─Block: 2-9                        [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-49              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-50              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-51               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-52               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-53              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-54                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-55               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-56               [-1, 197, 768]            --\n",
      "|    └─Block: 2-10                       [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-57              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-58              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-59               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-60               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-61              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-62                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-63               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-64               [-1, 197, 768]            --\n",
      "|    └─Block: 2-11                       [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-65              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-66              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-67               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-68               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-69              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-70                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-71               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-72               [-1, 197, 768]            --\n",
      "|    └─Block: 2-12                       [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-73              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-74              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-75               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-76               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-77              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-78                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-79               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-80               [-1, 197, 768]            --\n",
      "|    └─Block: 2-13                       [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-81              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-82              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-83               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-84               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-85              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-86                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-87               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-88               [-1, 197, 768]            --\n",
      "|    └─Block: 2-14                       [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-89              [-1, 197, 768]            1,536\n",
      "|    |    └─Attention: 3-90              [-1, 197, 768]            2,362,368\n",
      "|    |    └─Identity: 3-91               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-92               [-1, 197, 768]            --\n",
      "|    |    └─LayerNorm: 3-93              [-1, 197, 768]            1,536\n",
      "|    |    └─Mlp: 3-94                    [-1, 197, 768]            4,722,432\n",
      "|    |    └─Identity: 3-95               [-1, 197, 768]            --\n",
      "|    |    └─Identity: 3-96               [-1, 197, 768]            --\n",
      "├─LayerNorm: 1-6                         [-1, 197, 768]            1,536\n",
      "├─Identity: 1-7                          [-1, 768]                 --\n",
      "├─Dropout: 1-8                           [-1, 768]                 --\n",
      "├─Linear: 1-9                            [-1, 2]                   1,538\n",
      "==========================================================================================\n",
      "Total params: 85,648,130\n",
      "Trainable params: 85,648,130\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 455.99\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 154.67\n",
      "Params size (MB): 326.72\n",
      "Estimated Total Size (MB): 481.97\n",
      "==========================================================================================\n",
      "Epoch [1/50], Train Loss: 0.3710, LR: 0.001000                                  \n",
      "Validation Loss: 0.0082, F1: 0.8624\n",
      "Saved Best Model at epoch 1 with F1 score: 0.8624\n",
      "Epoch [2/50], Train Loss: 0.2539, LR: 0.001000                                  \n",
      "Validation Loss: 0.0067, F1: 0.8825\n",
      "Saved Best Model at epoch 2 with F1 score: 0.8825\n",
      "Epoch [3/50], Train Loss: 0.2277, LR: 0.001000                                  \n",
      "Validation Loss: 0.0064, F1: 0.8750\n",
      "Epoch [4/50], Train Loss: 0.2201, LR: 0.001000                                  \n",
      "Validation Loss: 0.0070, F1: 0.8463\n",
      "Epoch [5/50], Train Loss: 0.2094, LR: 0.000100                                  \n",
      "Validation Loss: 0.0060, F1: 0.8870\n",
      "Saved Best Model at epoch 5 with F1 score: 0.8870\n",
      "Epoch [6/50], Train Loss: 0.1641, LR: 0.000100                                  \n",
      "Validation Loss: 0.0053, F1: 0.9058\n",
      "Saved Best Model at epoch 6 with F1 score: 0.9058\n",
      "Epoch [7/50], Train Loss: 0.1532, LR: 0.000100                                  \n",
      "Validation Loss: 0.0051, F1: 0.9091\n",
      "Saved Best Model at epoch 7 with F1 score: 0.9091\n",
      "Epoch [8/50], Train Loss: 0.1452, LR: 0.000100                                  \n",
      "Validation Loss: 0.0050, F1: 0.9137\n",
      "Saved Best Model at epoch 8 with F1 score: 0.9137\n",
      "Epoch [9/50], Train Loss: 0.1417, LR: 0.000100                                  \n",
      "Validation Loss: 0.0048, F1: 0.9199\n",
      "Saved Best Model at epoch 9 with F1 score: 0.9199\n",
      "Epoch [10/50], Train Loss: 0.1365, LR: 0.000010                                 \n",
      "Validation Loss: 0.0050, F1: 0.9154\n",
      "Epoch [11/50], Train Loss: 0.1240, LR: 0.000010                                 \n",
      "Validation Loss: 0.0047, F1: 0.9186\n",
      "Epoch [12/50], Train Loss: 0.1175, LR: 0.000010                                 \n",
      "Validation Loss: 0.0046, F1: 0.9216\n",
      "Saved Best Model at epoch 12 with F1 score: 0.9216\n",
      "Epoch [13/50], Train Loss: 0.1138, LR: 0.000010                                 \n",
      "Validation Loss: 0.0046, F1: 0.9212\n",
      "Epoch [14/50], Train Loss: 0.1109, LR: 0.000010                                 \n",
      "Validation Loss: 0.0046, F1: 0.9205\n",
      "Epoch [15/50], Train Loss: 0.1078, LR: 0.000001                                 \n",
      "Validation Loss: 0.0047, F1: 0.9198\n",
      "Epoch [16/50], Train Loss: 0.1043, LR: 0.000001                                 \n",
      "Validation Loss: 0.0046, F1: 0.9217\n",
      "Saved Best Model at epoch 16 with F1 score: 0.9217\n",
      "Epoch [17/50], Train Loss: 0.1035, LR: 0.000001                                 \n",
      "Validation Loss: 0.0046, F1: 0.9206\n",
      "Epoch [18/50], Train Loss: 0.1031, LR: 0.000001                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [19/50], Train Loss: 0.1027, LR: 0.000001                                 \n",
      "Validation Loss: 0.0046, F1: 0.9203\n",
      "Epoch [20/50], Train Loss: 0.1023, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9185\n",
      "Epoch [21/50], Train Loss: 0.1018, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9192\n",
      "Epoch [22/50], Train Loss: 0.1018, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9195\n",
      "Epoch [23/50], Train Loss: 0.1017, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9205\n",
      "Epoch [24/50], Train Loss: 0.1017, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [25/50], Train Loss: 0.1017, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [26/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [27/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [28/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [29/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [30/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [31/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [32/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [33/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [34/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [35/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [36/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [37/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [38/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [39/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [40/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [41/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [42/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [43/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [44/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [45/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [46/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [47/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [48/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [49/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "Epoch [50/50], Train Loss: 0.1016, LR: 0.000000                                 \n",
      "Validation Loss: 0.0046, F1: 0.9202\n",
      "\n",
      "Training completed in 5895.0s\n",
      "\n",
      "--- Overall Metrics ---\n",
      "Precision: 0.9244\n",
      "Recall: 0.9162\n",
      "F1 Score: 0.9202\n",
      "Accuracy: 0.9499\n",
      "Balanced Accuracy: 0.9162\n"
     ]
    }
   ],
   "source": [
    "!python train-vt.py --model_name vit_base_patch16_224 --data_dir AMLDataset/AML --num_classes 2 --num_epochs 50 --batch_size 32 --learning_rate 0.001 --checkpoint_path model_checkpoints/AML/vit --pretrained_path model_checkpoints/ALL/vit/vit_base_patch16_224_best.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1a182-db73-4459-989d-8b143751831c",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Inference on unseen AML Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ddd70f-02fb-4832-98e7-9336e78790e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TL model with unseen ALL images again to see if TL helped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42ebac13-8277-4b69-b9d9-d3afffccf3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████| 15/15 [00:01<00:00,  8.55it/s, acc=0.32]\n",
      "\n",
      "Evaluation Results:\n",
      "Precision: 0.4921\n",
      "Recall: 0.4998\n",
      "F1: 0.2468\n",
      "Accuracy: 0.3198\n",
      "Balanced accuracy: 0.4998\n"
     ]
    }
   ],
   "source": [
    "!python evaluate_vt.py --model_name vit_base_patch16_224 --data_dir ALL_Unseen/ --model_path model_checkpoints/AML/vit/vit_base_patch16_224_best.pth --num_classes 2 --batch_size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55812da6-1057-4fd1-9b9e-1d66e9bea64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TL model with unseen AML images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "982df6cc-cada-4491-a24c-00804a0e0e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████| 29/29 [00:03<00:00,  7.54it/s, acc=0.957]\n",
      "\n",
      "Evaluation Results:\n",
      "Precision: 0.9352\n",
      "Recall: 0.9298\n",
      "F1: 0.9325\n",
      "Accuracy: 0.9575\n",
      "Balanced accuracy: 0.9298\n"
     ]
    }
   ],
   "source": [
    "!python evaluate_vt.py --model_name vit_base_patch16_224 --data_dir AML_Unseen/ --model_path model_checkpoints/AML/vit/vit_base_patch16_224_best.pth --num_classes 2 --batch_size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac730a26-c5e1-4468-9e17-20123a665203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training AML Only without TF weights to Compare with TF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c12659-b0bb-4f60-b17f-a9d481d053c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7638fbb8-d398-4998-985d-7afd087a6996",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.5064, LR: 0.001000                                  \n",
      "Validation: 100%|███████████| 164/164 [00:15<00:00, 10.83it/s, val_loss=0.00848]\n",
      "Validation Loss: 0.0114, F1: 0.6030\n",
      "Saved Best Model at epoch 1 with F1 score: 0.6030\n",
      "Epoch [2/50], Train Loss: 0.2849, LR: 0.001000                                  \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.89it/s, val_loss=0.0152]\n",
      "Validation Loss: 0.0118, F1: 0.4493\n",
      "Epoch [3/50], Train Loss: 0.2635, LR: 0.001000                                  \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.88it/s, val_loss=0.0212]\n",
      "Validation Loss: 0.0079, F1: 0.8422\n",
      "Saved Best Model at epoch 3 with F1 score: 0.8422\n",
      "Epoch [4/50], Train Loss: 0.2354, LR: 0.001000                                  \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.88it/s, val_loss=0.0161]\n",
      "Validation Loss: 0.0066, F1: 0.8856\n",
      "Saved Best Model at epoch 4 with F1 score: 0.8856\n",
      "Epoch [5/50], Train Loss: 0.2215, LR: 0.000100                                  \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.0138]\n",
      "Validation Loss: 0.0064, F1: 0.8868\n",
      "Saved Best Model at epoch 5 with F1 score: 0.8868\n",
      "Epoch [6/50], Train Loss: 0.1797, LR: 0.000100                                  \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.88it/s, val_loss=0.0186]\n",
      "Validation Loss: 0.0056, F1: 0.9055\n",
      "Saved Best Model at epoch 6 with F1 score: 0.9055\n",
      "Epoch [7/50], Train Loss: 0.1708, LR: 0.000100                                  \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.89it/s, val_loss=0.0185]\n",
      "Validation Loss: 0.0052, F1: 0.9122\n",
      "Saved Best Model at epoch 7 with F1 score: 0.9122\n",
      "Epoch [8/50], Train Loss: 0.1655, LR: 0.000100                                  \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.0294]\n",
      "Validation Loss: 0.0052, F1: 0.9088\n",
      "Epoch [9/50], Train Loss: 0.1613, LR: 0.000100                                  \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.0136]\n",
      "Validation Loss: 0.0050, F1: 0.9135\n",
      "Saved Best Model at epoch 9 with F1 score: 0.9135\n",
      "Epoch [10/50], Train Loss: 0.1559, LR: 0.000010                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.0191]\n",
      "Validation Loss: 0.0051, F1: 0.9093\n",
      "Epoch [11/50], Train Loss: 0.1469, LR: 0.000010                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.0072]\n",
      "Validation Loss: 0.0050, F1: 0.9086\n",
      "Epoch [12/50], Train Loss: 0.1426, LR: 0.000010                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.0145]\n",
      "Validation Loss: 0.0049, F1: 0.9093\n",
      "Epoch [13/50], Train Loss: 0.1403, LR: 0.000010                                 \n",
      "Validation: 100%|███████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.00747]\n",
      "Validation Loss: 0.0049, F1: 0.9086\n",
      "Epoch [14/50], Train Loss: 0.1385, LR: 0.000010                                 \n",
      "Validation: 100%|███████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.00901]\n",
      "Validation Loss: 0.0048, F1: 0.9114\n",
      "Epoch [15/50], Train Loss: 0.1369, LR: 0.000001                                 \n",
      "Validation: 100%|█████████████| 164/164 [00:15<00:00, 10.88it/s, val_loss=0.012]\n",
      "Validation Loss: 0.0048, F1: 0.9121\n",
      "Epoch [16/50], Train Loss: 0.1338, LR: 0.000001                                 \n",
      "Validation: 100%|███████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.00995]\n",
      "Validation Loss: 0.0048, F1: 0.9120\n",
      "Epoch [17/50], Train Loss: 0.1332, LR: 0.000001                                 \n",
      "Validation: 100%|███████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.00931]\n",
      "Validation Loss: 0.0048, F1: 0.9119\n",
      "Epoch [18/50], Train Loss: 0.1329, LR: 0.000001                                 \n",
      "Validation: 100%|███████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.00906]\n",
      "Validation Loss: 0.0048, F1: 0.9118\n",
      "Epoch [19/50], Train Loss: 0.1325, LR: 0.000001                                 \n",
      "Validation: 100%|███████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.00907]\n",
      "Validation Loss: 0.0048, F1: 0.9120\n",
      "Epoch [20/50], Train Loss: 0.1322, LR: 0.000000                                 \n",
      "Validation: 100%|███████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.00874]\n",
      "Validation Loss: 0.0048, F1: 0.9128\n",
      "Epoch [21/50], Train Loss: 0.1319, LR: 0.000000                                 \n",
      "Validation: 100%|███████████| 164/164 [00:15<00:00, 10.88it/s, val_loss=0.00876]\n",
      "Validation Loss: 0.0048, F1: 0.9123\n",
      "Epoch [22/50], Train Loss: 0.1318, LR: 0.000000                                 \n",
      "Validation: 100%|███████████| 164/164 [00:15<00:00, 10.85it/s, val_loss=0.00878]\n",
      "Validation Loss: 0.0048, F1: 0.9123\n",
      "Epoch [23/50], Train Loss: 0.1317, LR: 0.000000                                 \n",
      "Validation: 100%|███████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.00878]\n",
      "Validation Loss: 0.0048, F1: 0.9121\n",
      "Epoch [24/50], Train Loss: 0.1316, LR: 0.000000                                 \n",
      "Validation: 100%|███████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.00879]\n",
      "Validation Loss: 0.0048, F1: 0.9119\n",
      "Epoch [25/50], Train Loss: 0.1316, LR: 0.000000                                 \n",
      "Validation: 100%|███████████| 164/164 [00:15<00:00, 10.85it/s, val_loss=0.00879]\n",
      "Validation Loss: 0.0048, F1: 0.9119\n",
      "Epoch [26/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9119\n",
      "Epoch [27/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9119\n",
      "Epoch [28/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|███████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.00879]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [29/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [30/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [31/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [32/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [33/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.88it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [34/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [35/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [36/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [37/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [38/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.89it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [39/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [40/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.88it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [41/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.87it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [42/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [43/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [44/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.85it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [45/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.88it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [46/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [47/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [48/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [49/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.86it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "Epoch [50/50], Train Loss: 0.1315, LR: 0.000000                                 \n",
      "Validation: 100%|████████████| 164/164 [00:15<00:00, 10.85it/s, val_loss=0.0088]\n",
      "Validation Loss: 0.0048, F1: 0.9116\n",
      "\n",
      "Training completed in 5887.5s\n",
      "\n",
      "--- Overall Metrics ---\n",
      "Precision: 0.9209\n",
      "Recall: 0.9030\n",
      "F1 Score: 0.9116\n",
      "Accuracy: 0.9451\n",
      "Balanced Accuracy: 0.9030\n"
     ]
    }
   ],
   "source": [
    "# start training AML Model\n",
    "!python train-vt.py --model_name vit_base_patch16_224 --data_dir AMLDataset/AML/ --num_classes 2 --num_epochs 50 --batch_size 32 --learning_rate 0.001 --checkpoint_path model_checkpoints/AML_Only/vit/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62570d38-6369-494f-b32a-84f1d1e2a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test AML_Only model on AML Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06dd8ff8-7022-49f1-be18-f578af76f01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████| 29/29 [00:03<00:00,  9.59it/s, acc=0.944]\n",
      "\n",
      "Evaluation Results:\n",
      "Precision: 0.9090\n",
      "Recall: 0.9174\n",
      "F1: 0.9131\n",
      "Accuracy: 0.9444\n",
      "Balanced accuracy: 0.9174\n"
     ]
    }
   ],
   "source": [
    "!python evaluate_vt.py --model_name vit_base_patch16_224 --data_dir AML_Unseen/ --model_path model_checkpoints/AML_Only/vit/vit_base_patch16_224_best.pth --num_classes 2 --batch_size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41db8c9-c9cd-4564-9741-562740974db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- **************-----------------***********---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea415e52-09ee-4685-87cb-cbdd674156f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- **************-----------------***********---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cbb2e1-3ed9-4954-94cf-cef33555c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- **************-----------------***********---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d3fc8a-8d6b-4e2d-846a-82d4354bab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- **************-----------------***********---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb548a4-c2a9-4bb1-aae8-28808e7c7492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best AML model weights to TF on ALL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136541b1-ffef-4e49-b7e7-845049f2a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train-mobilenetv2.py --model_name mobilenetv2 --data_dir TLDataset/ALL/PKG-C-NMC2019 --num_classes 2 --num_epochs 150 --batch_size 64 --learning_rate 0.01 --momentum 0.9 --checkpoint_path model_checkpoints/AML_Pretrained/mobilenetv2 --pretrained_path model_checkpoints/AML_Only/mobilenetv2/mobilenetv2_best_epoch_104.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60a038-17b9-4544-ba4b-6ce9644edeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF Model Validation on Unseen ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af42bd7-8482-42bc-8ba8-96a09bdf5c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate-mobilenetv2.py --model_name mobilenetv2 --data_dir ALL_Unseen/ --model_path model_checkpoints/AML_Pretrained/mobilenetv2/mobilenetv2_best_epoch_100.pth --num_classes 2 --batch_size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b01a06-a5af-409c-ae42-aa993c82fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF Model Validation on Unseen AML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f26b00b-e1aa-4bba-83a3-33492cd7e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate.py --model_name resnet50 --data_dir AML_Unseen/ --model_path model_checkpoints/ALL_Pretrained/resnet50_best_epoch_76.pth --num_classes 2 --batch_size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37443998-4fa8-4b55-bed9-1e5c724d39c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
